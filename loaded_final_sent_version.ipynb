{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECM_23CVMI2n"
      },
      "source": [
        "# import\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "E6-chVNF54NP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nl99nUKzMI2q",
        "outputId": "8e820ac6-b8b5-41f6-fa8d-0713d2662fbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "we make recommendation based on the similarity of the items for food recipes based on the ingredients and recipe specifications using the cosine similarity method\n",
        "and train word2vec model from scratch using gensim library on my dataset and then use the trained model to find the similarity between the ingredients of the recipes.\n",
        "\"\"\"\n",
        "\n",
        "# Importing the libraries\n",
        "# !pip install textblob\n",
        "# !pip install POT\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('wordnet')\n",
        "# show all columns and rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# # Importing the dataset\n",
        "# df = pd.read_csv('https://github.com/eslamahmedamit/food-recipes-recsys/blob/87cf871934c5eb6adb16759ab0d190fba921211a/recipes_data_graduation_project.csv?raw=true')\n",
        "\n",
        "# # Data Preprocessing\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# # https://github.com/eslamahmedamit/food-recipes-recsys/blob/87cf871934c5eb6adb16759ab0d190fba921211a/recipes_data_graduation_project.csv\n",
        "# df = pd.read_csv('https://github.com/eslamahmedamit/food-recipes-recsys/blob/87cf871934c5eb6adb16759ab0d190fba921211a/recipes_data_graduation_project.csv?raw=true')\n",
        "# # df"
      ],
      "metadata": {
        "id": "lyZyOR8LRbMZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/18obaPDPu58OnzhnJgVYLzg1C-XR1ER-4/view\n",
        "# https://drive.google.com/file/d/1vw6D0GTM8zAg7U_O0PAEwIEw16M-rt9X/view?usp=sharing\n",
        "!gdown --id \"18obaPDPu58OnzhnJgVYLzg1C-XR1ER-4\"\n",
        "!gdown --id \"1vw6D0GTM8zAg7U_O0PAEwIEw16M-rt9X\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhDYtjp8lD-i",
        "outputId": "1898eee1-ba73-4717-89d2-c9f5fd34a010"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18obaPDPu58OnzhnJgVYLzg1C-XR1ER-4\n",
            "To: /content/out_text_data.csv\n",
            "100% 824M/824M [00:06<00:00, 126MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vw6D0GTM8zAg7U_O0PAEwIEw16M-rt9X\n",
            "To: /content/word2vec.model\n",
            "100% 17.1M/17.1M [00:00<00:00, 64.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = pd.read_csv('out_text_data.csv')\n",
        "word2vec_model = Word2Vec.load(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "xOojYVjvx9gS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWCBa9yBMI2t"
      },
      "source": [
        "# Recommendation for Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4R_HMl1MI2t"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "13a2q191MI2u"
      },
      "outputs": [],
      "source": [
        "# print text cleaning steps\n",
        "'''\n",
        " text cleaning steps\n",
        "    1- remove html tags\n",
        "    2- remove special characters\n",
        "    3- remove punctuation\n",
        "    4- remove stopwords\n",
        "    5- lemmatization\n",
        "    6- lowercase\n",
        "    7- remove numbers\n",
        "    8- remove extra spaces\n",
        "    9- remove single characters\n",
        "    10- remove short words\n",
        "\n",
        "'''\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# 1- remove html tags\n",
        "def remove_html_tags(text):\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "# 2- remove special characters\n",
        "def remove_special_characters(text):\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "# 3- remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "# 4- remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    return ' '.join(filtered_sentence)\n",
        "\n",
        "# 5- lemmatization\n",
        "def lemmatization(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_tokens = word_tokenize(text)\n",
        "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_tokens])\n",
        "    return lemmatized_output\n",
        "\n",
        "# 6- lowercase\n",
        "def lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "# 7- remove numbers\n",
        "def remove_numbers(text):\n",
        "    pattern = r'[0-9]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "# 8- remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    pattern = r'\\s+'\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    return text\n",
        "\n",
        "# 9- remove single characters\n",
        "def remove_single_characters(text):\n",
        "    pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    return text\n",
        "\n",
        "# 10- remove short words\n",
        "def remove_short_words(text):\n",
        "    pattern = r'\\W*\\b\\w{1,3}\\b'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "# 11 - conver plural to singular using textblob library\n",
        "def singular(text):\n",
        "    from textblob import TextBlob\n",
        "    text = TextBlob(text)\n",
        "    text = text.words.singularize()\n",
        "    return text\n",
        "\n",
        "# 12 - remove most 3 common words ['tablespoon','teaspoon','cup']\n",
        "def remove_common_words(text):\n",
        "    common_words = ['tablespoon','teaspoon','cup']\n",
        "    text = ' '.join([word for word in text.split() if word not in common_words])\n",
        "    return text\n",
        "\n",
        "\n",
        "# apply all text cleaning steps\n",
        "def text_cleaning(text):\n",
        "    text = remove_html_tags(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_punctuation(text)\n",
        "    # print(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatization(text)\n",
        "    text = lowercase(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    text = remove_single_characters(text)\n",
        "    # text = remove_short_words(text)\n",
        "    # add text to string\n",
        "    text = remove_common_words(text)\n",
        "    text = singular(text)\n",
        "    text = ' '.join(text)\n",
        "\n",
        "    try:\n",
        "      pbar.update(1)\n",
        "    except:\n",
        "      pass\n",
        "    return text\n",
        "\n",
        "# apply text cleaning steps on text data\n",
        "# for feature in text_features:\n",
        "#     text_data[feature] = text_data[feature].apply(text_cleaning)\n",
        "\n",
        "\n",
        "# create function to apply with progress bar\n",
        "def apply_with_bar(org_data,column):\n",
        "    global pbar\n",
        "\n",
        "    pbar = tqdm(total=len(org_data))\n",
        "\n",
        "    org_data[f'{column}_cleaned'] = org_data[column].apply(text_cleaning)\n",
        "    print(f'Done cleaning {column}')\n",
        "    pbar.close()\n",
        "\n",
        "# # apply function to all text columns\n",
        "# clean_features = ['summary']\n",
        "# clean_features = ['name','summary','ingredients']\n",
        "# clean_features = ['name', 'category', 'summary', 'ingredients','diet_type']\n",
        "# for column in clean_features:\n",
        "#     apply_with_bar(text_data,column)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommend Function"
      ],
      "metadata": {
        "id": "MyxEK2In6Lnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "daXQI3IgMI2w"
      },
      "outputs": [],
      "source": [
        "# get similarity between two ingredients with different teqnique\n",
        "# convert the ingredients to vector if the ingredients is in the vocabulary using get_vector_pre_trained function\n",
        "# edit the function to split words\n",
        "def get_vector_pre_trained(x,model):\n",
        "    s_vec = w_vec = np.zeros(model.vector_size)\n",
        "\n",
        "    for word in x.split():\n",
        "        if word in model:\n",
        "            w_vec = model[word]\n",
        "            s_vec = s_vec + w_vec\n",
        "    # if s_vec.all() == 0:\n",
        "    #     s_vec = np.zeros(256)\n",
        "    return s_vec\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_vectors(vector_str):\n",
        "    # Use regular expressions to convert str to float\n",
        "    vector_str = vector_str.replace(\"[[]]\", '')\n",
        "    vector_str = re.sub(r\"\\n\", \"\", vector_str)\n",
        "    vector_str = re.sub(r\"\\[\", \"\", vector_str)\n",
        "    vector_str = re.sub(r\"\\]\", \"\", vector_str)\n",
        "\n",
        "    vector_str = re.sub(r\"  \", \" \", vector_str)\n",
        "    vector_str = vector_str.split(' ')\n",
        "\n",
        "    vector_str = [float(element) for element in vector_str if element != '']\n",
        "\n",
        "    return vector_str\n",
        "\n",
        "# type(edit_vectors(text_data['summary_vector'][4]))#[:20]\n",
        "\n",
        "\t# ingredients_vector\tname_vector\tcategory_vector\tsummary_vector\tdiet_type_vector\tall_text_vector\n",
        "\n",
        "text_data['ingredients_vector'] = text_data['ingredients_vector'].apply(edit_vectors)\n",
        "text_data['name_vector'] = text_data['name_vector'].apply(edit_vectors)\n",
        "text_data['category_vector'] = text_data['category_vector'].apply(edit_vectors)\n",
        "text_data['summary_vector'] = text_data['summary_vector'].apply(edit_vectors)\n",
        "text_data['diet_type_vector'] = text_data['diet_type_vector'].apply(edit_vectors)\n",
        "text_data['all_text_vector'] = text_data['all_text_vector'].apply(edit_vectors)"
      ],
      "metadata": {
        "id": "PbzPceldmdqY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9M7Bc7P-MI2x"
      },
      "outputs": [],
      "source": [
        "# now we need to build a recommender system based on the ingredients, name, category, summary, diet_type to predict the best recipe for the user with high similarity\n",
        "# we will use cosine similarity to get the similarity between the user input and the recipes in the dataset\n",
        "# we will use the ingredients, name, category, summary, diet_type as features to predict the best recipe for the user\n",
        "\n",
        "def get_similar_recipe_full_model(test_df_input,no_of_recipes=5):\n",
        "    clean_features = ['name', 'category', 'summary', 'ingredients','diet_type']\n",
        "    for column in clean_features:\n",
        "        # apply_with_bar(test_df_input,column)\n",
        "        test_df_input[f'{column}_cleaned'] = test_df_input[column].apply(text_cleaning)\n",
        "\n",
        "    # get the vector of the input\n",
        "    ingredients_vector = get_vector_pre_trained(test_df_input['ingredients_cleaned'][0],word2vec_model.wv)\n",
        "    name_vector = get_vector_pre_trained(test_df_input['name_cleaned'][0],word2vec_model.wv)\n",
        "    category_vector = get_vector_pre_trained(test_df_input['category_cleaned'][0],word2vec_model.wv)\n",
        "    summary_vector = get_vector_pre_trained(test_df_input['summary_cleaned'][0],word2vec_model.wv)\n",
        "    diet_type_vector = get_vector_pre_trained(test_df_input['diet_type_cleaned'][0],word2vec_model.wv)\n",
        "\n",
        "    # try to abbreviation the previous code\n",
        "    # get the vector of the input\n",
        "\n",
        "\n",
        "    # get the cosine similarity between the input and the recipes in the dataset\n",
        "    text_data['ingredients_similarity'] = text_data['ingredients_vector'].apply(lambda x: word2vec_model.wv.cosine_similarities(ingredients_vector,[x])[0])\n",
        "    text_data['name_similarity'] = text_data['name_vector'].apply(lambda x: word2vec_model.wv.cosine_similarities(name_vector,[x])[0])\n",
        "    text_data['category_similarity'] = text_data['category_vector'].apply(lambda x: word2vec_model.wv.cosine_similarities(category_vector,[x])[0])\n",
        "    text_data['summary_similarity'] = text_data['summary_vector'].apply(lambda x: word2vec_model.wv.cosine_similarities(summary_vector,[x])[0])\n",
        "    text_data['diet_type_similarity'] = text_data['diet_type_vector'].apply(lambda x: word2vec_model.wv.cosine_similarities(diet_type_vector,[x])[0])\n",
        "    # get the mean of the similarity between the input and the recipes in the dataset\n",
        "    text_data['mean_similarity'] = (text_data['ingredients_similarity'] + text_data['name_similarity'] + text_data['category_similarity'] + text_data['summary_similarity'] + text_data['diet_type_similarity'])/5\n",
        "    # get the top 5 recipes with high similarity\n",
        "\n",
        "    top_recipes = text_data.sort_values(by='mean_similarity',ascending=False).head(no_of_recipes)\n",
        "    return top_recipes\n",
        "\n",
        "# test the function\n",
        "test_name = 'Macaroni and Cheese'\n",
        "test_category = 'main-dish'\n",
        "test_summary = 'This is a recipe for macaroni and cheese.'\n",
        "test_ingredients = 'macaroni, cheese, butter, milk'\n",
        "test_diet_type = 'Vegetarian'\n",
        "\n",
        "# add to dataframe\n",
        "\n",
        "test_df = pd.DataFrame({'name':[test_name],'category':[test_category],'summary':[test_summary],'ingredients':[test_ingredients],'diet_type':[test_diet_type]})\n",
        "\n",
        "# get_similar_recipe_full_model(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9zWUhKnnMI2x"
      },
      "outputs": [],
      "source": [
        "# make a function to get the top 5 recipes with high similarity but similar with free text input and with all text column\n",
        "def get_similar_recipe_free_text(test_text_input,no_of_recipes=5):\n",
        "    # get the vector of the input\n",
        "    text_vector = get_vector_pre_trained(test_text_input,word2vec_model.wv)\n",
        "    # get the cosine similarity between the input and the recipes in the dataset\n",
        "    text_data['text_similarity'] = text_data['all_text_vector'].apply(lambda x: word2vec_model.wv.cosine_similarities(text_vector,[x])[0])\n",
        "    # get the top 5 recipes with high similarity\n",
        "    top_recipes = text_data.sort_values(by='text_similarity',ascending=False).head(no_of_recipes)\n",
        "    return top_recipes\n",
        "\n",
        "\n",
        "# test the function\n",
        "test_text = 'This is a recipe for macaroni and cheese.'\n",
        "# get_similar_recipe_free_text(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4V_RVO7KMI2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "1937351f-1e16-41d6-8f6d-1a030ec62a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                                url  \\\n",
              "17093       17093  https://www.allrecipes.com/recipe/237064/chef-...   \n",
              "24911       24911    https://www.allrecipes.com/recipe/15343/menudo/   \n",
              "12759       12759  https://www.allrecipes.com/recipe/168646/aunti...   \n",
              "23658       23658  https://www.allrecipes.com/recipe/138016/brill...   \n",
              "343           343  https://www.allrecipes.com/recipe/274411/bucat...   \n",
              "\n",
              "                                                    name  \\\n",
              "17093                        Chef John's Homemade Cheese   \n",
              "24911                                             Menudo   \n",
              "12759                        Auntie Anita's Lobster Stew   \n",
              "23658                         Brilliant Sauteed Broccoli   \n",
              "343    Bucatini Cacio e Pepe (Roman Sheep Herder's Pa...   \n",
              "\n",
              "                    category  \\\n",
              "17093          world-cuisine   \n",
              "24911  soups-stews-and-chili   \n",
              "12759  soups-stews-and-chili   \n",
              "23658              side-dish   \n",
              "343            world-cuisine   \n",
              "\n",
              "                                                 summary  \\\n",
              "17093  Usually making something like fresh cheese at ...   \n",
              "24911  This dish depends on how much of each ingredie...   \n",
              "12759  Stirring is the most important thing in this m...   \n",
              "23658  If you want a slightly original restaurant-qua...   \n",
              "343    This peasant food comes from Roman sheep herde...   \n",
              "\n",
              "                                             ingredients  \\\n",
              "17093  1 quart whole milk ; 1 cup cultured buttermilk...   \n",
              "24911  2 pounds beef tripe ; 2  onions, chopped ; 4 (...   \n",
              "12759  2 (1 pound) Maine lobsters ; ½ cup butter ; 1 ...   \n",
              "23658  1 pound broccoli florets ; 3 tablespoons finel...   \n",
              "343    1 teaspoon salt ; 1 pound bucatini (dry) ; 2 c...   \n",
              "\n",
              "                         diet_type                   allergens  cuisine  \\\n",
              "17093   vegetarian, omnivore, keto                        milk  chinese   \n",
              "24911                     omnivore                no_allergens  chinese   \n",
              "12759   vegetarian, omnivore, keto  milk, crustacean_shellfish  unknown   \n",
              "23658  vegetarian, omnivore, paleo                        milk  chinese   \n",
              "343     vegetarian, omnivore, keto                        milk  chinese   \n",
              "\n",
              "                                        name_cleaned    category_cleaned  \\\n",
              "17093                      chef john homemade cheese        worldcuisine   \n",
              "24911                                         menudo  soupsstewsandchili   \n",
              "12759                      auntie anita lobster stew  soupsstewsandchili   \n",
              "23658                     brilliant sauteed broccoli            sidedish   \n",
              "343    bucatini cacio pepe roman sheep herder pastum        worldcuisine   \n",
              "\n",
              "                                         summary_cleaned  \\\n",
              "17093  usually making something like fresh cheese hom...   \n",
              "24911  thi dish depend much ingredient put it depend ...   \n",
              "12759  stirring important thing masterpiece otherwise...   \n",
              "23658  if want slightly original restaurantquality br...   \n",
              "343    thi peasant food come roman sheep herder littl...   \n",
              "\n",
              "                                     ingredients_cleaned  \\\n",
              "17093  quart whole milk cultured buttermilk lemon jui...   \n",
              "24911  pound beef tripe onion chopped ounce can white...   \n",
              "12759        pound maine lobster butter quart whole milk   \n",
              "23658  pound broccoli floret finely grated parmesan c...   \n",
              "343    salt pound bucatini dry finely grated pecorino...   \n",
              "\n",
              "               diet_type_cleaned  \\\n",
              "17093   vegetarian omnivore keto   \n",
              "24911                   omnivore   \n",
              "12759   vegetarian omnivore keto   \n",
              "23658  vegetarian omnivore paleo   \n",
              "343     vegetarian omnivore keto   \n",
              "\n",
              "                                                all_text  \\\n",
              "17093  chef john homemade cheese quart whole milk cul...   \n",
              "24911  menudo pound beef tripe onion chopped ounce ca...   \n",
              "12759  auntie anita lobster stew pound maine lobster ...   \n",
              "23658  brilliant sauteed broccoli pound broccoli flor...   \n",
              "343    bucatini cacio pepe roman sheep herder pastum ...   \n",
              "\n",
              "                                      ingredients_vector  \\\n",
              "17093  [-0.19837799, -0.06539053, 0.30719837, -0.1399...   \n",
              "24911  [-0.22396242, -0.05157039, 0.50392556, 0.06134...   \n",
              "12759  [-0.21986135, -0.1388417, 0.08782941, 0.123600...   \n",
              "23658  [0.05009192, -0.90001818, 0.87432666, -0.15795...   \n",
              "343    [0.13623747, -0.42690381, 0.52649315, -0.06549...   \n",
              "\n",
              "                                             name_vector  \\\n",
              "17093  [-0.23810511, 0.08556822, 0.05909911, 0.060571...   \n",
              "24911  [-0.06606941, 0.05903533, 0.11464968, -0.11381...   \n",
              "12759  [-0.0306272, 0.01226422, 0.01496476, 0.0333516...   \n",
              "23658  [0.05286979, -0.16882054, 0.07388257, 0.039960...   \n",
              "343    [-0.03108162, 0.07305712, -0.04639366, -0.2024...   \n",
              "\n",
              "                                         category_vector  \\\n",
              "17093  [0.09202719, -0.0477601, -0.12202831, 0.026606...   \n",
              "24911  [0.10139953, -0.07426593, 0.00211118, 0.048104...   \n",
              "12759  [0.10139953, -0.07426593, 0.00211118, 0.048104...   \n",
              "23658  [0.08671039, -0.08591148, -0.12258501, 0.04769...   \n",
              "343    [0.09202719, -0.0477601, -0.12202831, 0.026606...   \n",
              "\n",
              "                                          summary_vector  \\\n",
              "17093  [-1.25981323, 0.42215108, -1.39175358, 0.52366...   \n",
              "24911  [-0.5400863, 1.1556715, -0.75533601, 1.2593419...   \n",
              "12759  [-0.50716522, 1.4525462, -1.86576846, 0.747241...   \n",
              "23658  [-0.06667369, 0.29832426, -0.9436295, 0.032158...   \n",
              "343    [-0.10649867, 0.69508821, -0.53566286, 0.39503...   \n",
              "\n",
              "                                        diet_type_vector  \\\n",
              "17093  [0.01124892, 0.06244419, -0.08738073, -0.03586...   \n",
              "24911  [0.02420655, 0.05769445, -0.05357387, -0.07366...   \n",
              "12759  [0.01124892, 0.06244419, -0.08738073, -0.03586...   \n",
              "23658  [0.17145596, -0.03337804, -0.31693207, -0.1072...   \n",
              "343    [0.01124892, 0.06244419, -0.08738073, -0.03586...   \n",
              "\n",
              "                                         all_text_vector  \\\n",
              "17093  [-1.5930202, 0.45701287, -1.23486513, 0.435019...   \n",
              "24911  [-0.70451205, 1.14656496, -0.18822345, 1.18131...   \n",
              "12759  [-0.64500532, 1.31414699, -1.84824383, 0.91643...   \n",
              "23658  [0.29445437, -0.88980398, -0.43493735, -0.1453...   \n",
              "343    [0.1019333, 0.35592561, -0.26497241, 0.1178480...   \n",
              "\n",
              "       ingredients_similarity  name_similarity  category_similarity  \\\n",
              "17093                0.280709         0.089196             0.674928   \n",
              "24911                0.221661        -0.023317             0.639592   \n",
              "12759                0.386301         0.113893             0.639592   \n",
              "23658                0.269443         0.013735             0.668722   \n",
              "343                  0.232471         0.211110             0.674928   \n",
              "\n",
              "       summary_similarity  diet_type_similarity  mean_similarity  \\\n",
              "17093            0.195105              0.331145         0.314217   \n",
              "24911            0.083276              0.000451         0.184333   \n",
              "12759            0.022767              0.331145         0.298740   \n",
              "23658            0.062835              0.482987         0.299545   \n",
              "343              0.157826              0.331145         0.321496   \n",
              "\n",
              "       text_similarity  \n",
              "17093         0.398472  \n",
              "24911         0.382612  \n",
              "12759         0.374409  \n",
              "23658         0.374024  \n",
              "343           0.373737  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-186a12be-cdce-4805-bded-99cc5ab00fe3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>url</th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>summary</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>diet_type</th>\n",
              "      <th>allergens</th>\n",
              "      <th>cuisine</th>\n",
              "      <th>name_cleaned</th>\n",
              "      <th>category_cleaned</th>\n",
              "      <th>summary_cleaned</th>\n",
              "      <th>ingredients_cleaned</th>\n",
              "      <th>diet_type_cleaned</th>\n",
              "      <th>all_text</th>\n",
              "      <th>ingredients_vector</th>\n",
              "      <th>name_vector</th>\n",
              "      <th>category_vector</th>\n",
              "      <th>summary_vector</th>\n",
              "      <th>diet_type_vector</th>\n",
              "      <th>all_text_vector</th>\n",
              "      <th>ingredients_similarity</th>\n",
              "      <th>name_similarity</th>\n",
              "      <th>category_similarity</th>\n",
              "      <th>summary_similarity</th>\n",
              "      <th>diet_type_similarity</th>\n",
              "      <th>mean_similarity</th>\n",
              "      <th>text_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17093</th>\n",
              "      <td>17093</td>\n",
              "      <td>https://www.allrecipes.com/recipe/237064/chef-...</td>\n",
              "      <td>Chef John's Homemade Cheese</td>\n",
              "      <td>world-cuisine</td>\n",
              "      <td>Usually making something like fresh cheese at ...</td>\n",
              "      <td>1 quart whole milk ; 1 cup cultured buttermilk...</td>\n",
              "      <td>vegetarian, omnivore, keto</td>\n",
              "      <td>milk</td>\n",
              "      <td>chinese</td>\n",
              "      <td>chef john homemade cheese</td>\n",
              "      <td>worldcuisine</td>\n",
              "      <td>usually making something like fresh cheese hom...</td>\n",
              "      <td>quart whole milk cultured buttermilk lemon jui...</td>\n",
              "      <td>vegetarian omnivore keto</td>\n",
              "      <td>chef john homemade cheese quart whole milk cul...</td>\n",
              "      <td>[-0.19837799, -0.06539053, 0.30719837, -0.1399...</td>\n",
              "      <td>[-0.23810511, 0.08556822, 0.05909911, 0.060571...</td>\n",
              "      <td>[0.09202719, -0.0477601, -0.12202831, 0.026606...</td>\n",
              "      <td>[-1.25981323, 0.42215108, -1.39175358, 0.52366...</td>\n",
              "      <td>[0.01124892, 0.06244419, -0.08738073, -0.03586...</td>\n",
              "      <td>[-1.5930202, 0.45701287, -1.23486513, 0.435019...</td>\n",
              "      <td>0.280709</td>\n",
              "      <td>0.089196</td>\n",
              "      <td>0.674928</td>\n",
              "      <td>0.195105</td>\n",
              "      <td>0.331145</td>\n",
              "      <td>0.314217</td>\n",
              "      <td>0.398472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24911</th>\n",
              "      <td>24911</td>\n",
              "      <td>https://www.allrecipes.com/recipe/15343/menudo/</td>\n",
              "      <td>Menudo</td>\n",
              "      <td>soups-stews-and-chili</td>\n",
              "      <td>This dish depends on how much of each ingredie...</td>\n",
              "      <td>2 pounds beef tripe ; 2  onions, chopped ; 4 (...</td>\n",
              "      <td>omnivore</td>\n",
              "      <td>no_allergens</td>\n",
              "      <td>chinese</td>\n",
              "      <td>menudo</td>\n",
              "      <td>soupsstewsandchili</td>\n",
              "      <td>thi dish depend much ingredient put it depend ...</td>\n",
              "      <td>pound beef tripe onion chopped ounce can white...</td>\n",
              "      <td>omnivore</td>\n",
              "      <td>menudo pound beef tripe onion chopped ounce ca...</td>\n",
              "      <td>[-0.22396242, -0.05157039, 0.50392556, 0.06134...</td>\n",
              "      <td>[-0.06606941, 0.05903533, 0.11464968, -0.11381...</td>\n",
              "      <td>[0.10139953, -0.07426593, 0.00211118, 0.048104...</td>\n",
              "      <td>[-0.5400863, 1.1556715, -0.75533601, 1.2593419...</td>\n",
              "      <td>[0.02420655, 0.05769445, -0.05357387, -0.07366...</td>\n",
              "      <td>[-0.70451205, 1.14656496, -0.18822345, 1.18131...</td>\n",
              "      <td>0.221661</td>\n",
              "      <td>-0.023317</td>\n",
              "      <td>0.639592</td>\n",
              "      <td>0.083276</td>\n",
              "      <td>0.000451</td>\n",
              "      <td>0.184333</td>\n",
              "      <td>0.382612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12759</th>\n",
              "      <td>12759</td>\n",
              "      <td>https://www.allrecipes.com/recipe/168646/aunti...</td>\n",
              "      <td>Auntie Anita's Lobster Stew</td>\n",
              "      <td>soups-stews-and-chili</td>\n",
              "      <td>Stirring is the most important thing in this m...</td>\n",
              "      <td>2 (1 pound) Maine lobsters ; ½ cup butter ; 1 ...</td>\n",
              "      <td>vegetarian, omnivore, keto</td>\n",
              "      <td>milk, crustacean_shellfish</td>\n",
              "      <td>unknown</td>\n",
              "      <td>auntie anita lobster stew</td>\n",
              "      <td>soupsstewsandchili</td>\n",
              "      <td>stirring important thing masterpiece otherwise...</td>\n",
              "      <td>pound maine lobster butter quart whole milk</td>\n",
              "      <td>vegetarian omnivore keto</td>\n",
              "      <td>auntie anita lobster stew pound maine lobster ...</td>\n",
              "      <td>[-0.21986135, -0.1388417, 0.08782941, 0.123600...</td>\n",
              "      <td>[-0.0306272, 0.01226422, 0.01496476, 0.0333516...</td>\n",
              "      <td>[0.10139953, -0.07426593, 0.00211118, 0.048104...</td>\n",
              "      <td>[-0.50716522, 1.4525462, -1.86576846, 0.747241...</td>\n",
              "      <td>[0.01124892, 0.06244419, -0.08738073, -0.03586...</td>\n",
              "      <td>[-0.64500532, 1.31414699, -1.84824383, 0.91643...</td>\n",
              "      <td>0.386301</td>\n",
              "      <td>0.113893</td>\n",
              "      <td>0.639592</td>\n",
              "      <td>0.022767</td>\n",
              "      <td>0.331145</td>\n",
              "      <td>0.298740</td>\n",
              "      <td>0.374409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23658</th>\n",
              "      <td>23658</td>\n",
              "      <td>https://www.allrecipes.com/recipe/138016/brill...</td>\n",
              "      <td>Brilliant Sauteed Broccoli</td>\n",
              "      <td>side-dish</td>\n",
              "      <td>If you want a slightly original restaurant-qua...</td>\n",
              "      <td>1 pound broccoli florets ; 3 tablespoons finel...</td>\n",
              "      <td>vegetarian, omnivore, paleo</td>\n",
              "      <td>milk</td>\n",
              "      <td>chinese</td>\n",
              "      <td>brilliant sauteed broccoli</td>\n",
              "      <td>sidedish</td>\n",
              "      <td>if want slightly original restaurantquality br...</td>\n",
              "      <td>pound broccoli floret finely grated parmesan c...</td>\n",
              "      <td>vegetarian omnivore paleo</td>\n",
              "      <td>brilliant sauteed broccoli pound broccoli flor...</td>\n",
              "      <td>[0.05009192, -0.90001818, 0.87432666, -0.15795...</td>\n",
              "      <td>[0.05286979, -0.16882054, 0.07388257, 0.039960...</td>\n",
              "      <td>[0.08671039, -0.08591148, -0.12258501, 0.04769...</td>\n",
              "      <td>[-0.06667369, 0.29832426, -0.9436295, 0.032158...</td>\n",
              "      <td>[0.17145596, -0.03337804, -0.31693207, -0.1072...</td>\n",
              "      <td>[0.29445437, -0.88980398, -0.43493735, -0.1453...</td>\n",
              "      <td>0.269443</td>\n",
              "      <td>0.013735</td>\n",
              "      <td>0.668722</td>\n",
              "      <td>0.062835</td>\n",
              "      <td>0.482987</td>\n",
              "      <td>0.299545</td>\n",
              "      <td>0.374024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>343</td>\n",
              "      <td>https://www.allrecipes.com/recipe/274411/bucat...</td>\n",
              "      <td>Bucatini Cacio e Pepe (Roman Sheep Herder's Pa...</td>\n",
              "      <td>world-cuisine</td>\n",
              "      <td>This peasant food comes from Roman sheep herde...</td>\n",
              "      <td>1 teaspoon salt ; 1 pound bucatini (dry) ; 2 c...</td>\n",
              "      <td>vegetarian, omnivore, keto</td>\n",
              "      <td>milk</td>\n",
              "      <td>chinese</td>\n",
              "      <td>bucatini cacio pepe roman sheep herder pastum</td>\n",
              "      <td>worldcuisine</td>\n",
              "      <td>thi peasant food come roman sheep herder littl...</td>\n",
              "      <td>salt pound bucatini dry finely grated pecorino...</td>\n",
              "      <td>vegetarian omnivore keto</td>\n",
              "      <td>bucatini cacio pepe roman sheep herder pastum ...</td>\n",
              "      <td>[0.13623747, -0.42690381, 0.52649315, -0.06549...</td>\n",
              "      <td>[-0.03108162, 0.07305712, -0.04639366, -0.2024...</td>\n",
              "      <td>[0.09202719, -0.0477601, -0.12202831, 0.026606...</td>\n",
              "      <td>[-0.10649867, 0.69508821, -0.53566286, 0.39503...</td>\n",
              "      <td>[0.01124892, 0.06244419, -0.08738073, -0.03586...</td>\n",
              "      <td>[0.1019333, 0.35592561, -0.26497241, 0.1178480...</td>\n",
              "      <td>0.232471</td>\n",
              "      <td>0.211110</td>\n",
              "      <td>0.674928</td>\n",
              "      <td>0.157826</td>\n",
              "      <td>0.331145</td>\n",
              "      <td>0.321496</td>\n",
              "      <td>0.373737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-186a12be-cdce-4805-bded-99cc5ab00fe3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-186a12be-cdce-4805-bded-99cc5ab00fe3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-186a12be-cdce-4805-bded-99cc5ab00fe3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Make final function merge the two functions together based on mode parameter to get free text mode or not full model\n",
        "# make the function input as a dictionary\n",
        "def get_similar_recipe(user_input):\n",
        "    if user_input['mode']== 'full_model':\n",
        "        # convert to dataframe from dictionary to dataframe using keys as columns\n",
        "        user_input_df = pd.DataFrame(test_input,index=[0])\n",
        "        # user_input_df = pd.DataFrame(user_input['name'],user_input['category'],user_input['summary'],user_input['ingredients'],user_input['diet_type'])\n",
        "\n",
        "        return get_similar_recipe_full_model(user_input_df,user_input['no_of_recipes'])\n",
        "    elif user_input['mode'] == 'free_text':\n",
        "        return get_similar_recipe_free_text(user_input['text'],user_input['no_of_recipes'])\n",
        "    else:\n",
        "        return 'Please enter the correct mode'\n",
        "\n",
        "\n",
        "# test the function\n",
        "test_input = {'name':'Macaroni and Cheese','category':'main-dish','summary':'This is a recipe for macaroni and cheese.',\n",
        "              'ingredients':'macaroni, cheese, butter, milk','diet_type':'Vegetarian',\n",
        "              'mode':'full_model','no_of_recipes':5}\n",
        "\n",
        "\n",
        "get_similar_recipe(test_input)\n",
        "\n",
        "# test the function with free text mode\n",
        "test_input = {'text':'This is a recipe for macaroni and cheese.','mode':'free_text','no_of_recipes':5}\n",
        "get_similar_recipe(test_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8DStKjC56wA",
        "outputId": "d708e05d-22dd-49ce-e7f8-7ef8d2e20318"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 90.48839235305786 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "61wCaOg9MI2x"
      },
      "outputs": [],
      "source": [
        "# !pip install flask\n",
        "# !pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yOmw_l81MI2x"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# from pyngrok import ngrok\n",
        "# from flask import Flask, request, jsonify\n",
        "# import os\n",
        "\n",
        "# app = Flask(__name__)\n",
        "# # make app config \"ENV\" = \"development\" to make the app run in development mode\n",
        "# app.config[\"ENV\"] = \"development\"\n",
        "# app.config[\"USE_NGROK\"] = True\n",
        "\n",
        "\n",
        "# @app.route('/get-recipe', methods=['POST'])\n",
        "# def get_recipe():\n",
        "\n",
        "#     json_data = request.get_json()  # Get the JSON data from the request\n",
        "#     print(json_data)\n",
        "\n",
        "#     # test_input = json_data['test_input']  # Extract the required input from the JSON\n",
        "#     # print(test_input)\n",
        "#     result = get_similar_recipe(json_data).to_json()  # Call your function with the input\n",
        "#     print(\"result\", jsonify(result)  )\n",
        "#     return jsonify(result)  # Return the result as a JSON response\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LsLowm89MI2x"
      },
      "outputs": [],
      "source": [
        "# if __name__ == '__main__':\n",
        "#     app.run(host=\"localhost\",port=13950, debug=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEUnze7LMI2x"
      },
      "source": [
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}